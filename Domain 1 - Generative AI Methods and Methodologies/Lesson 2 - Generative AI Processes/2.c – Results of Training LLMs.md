# Lesson 2.c – Results of Training LLMs

### 🎯 Lesson Objective
Explore where large language models (LLMs) get their data, how multiple data sources affect the output, and why it's important to approach generative AI responses with critical thinking.

---

## 🧠 Where Do LLMs Get Their Data?

- LLMs like **Google Gemini** and **ChatGPT** get their information from **many different sources**.
- These sources vary widely and may include publicly available text, licensed data, or curated web content.

---

## ⚠️ Dynamic vs. Static Knowledge

- **Google Gemini**: Answers may come from **dynamic or real-time sources**, depending on the engine's design.
- **ChatGPT**: Adds a note that its **knowledge is static**—it does not always include the most current information.

> Outputs may **differ based on the sources used**, how recently the model was updated, and how it interprets prompts.

---

## 🔍 The Impact of Diverse Data Sources

- Generative AI tools will **reflect the variety of perspectives** they were trained on.
- Especially in **high-opinion areas** such as:
  - Politics
  - Religion
  - Cultural practices
  - Health and wellness

> These topics naturally produce **differing outputs** depending on wording, source material, and model architecture.

---

## 🧭 Critical Use of AI Outputs

- Users should **not treat generative AI content as inherently factual**.
- Instead, practice the same caution used with any information source:
  - Cross-check facts
  - Consider the context
  - Be mindful of bias in both prompt wording and model behavior

---

## 💡 Key Insight

Generative AI doesn't generate a single "truth"—it generates *plausible responses* based on training and available data. Treat its output as a helpful draft or insight, not a definitive source.

