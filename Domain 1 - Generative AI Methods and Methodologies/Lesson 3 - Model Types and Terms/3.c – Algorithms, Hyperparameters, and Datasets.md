# Lesson 3.c – Algorithms, Hyperparameters, and Datasets

### 🎯 Lesson Objective
Clarify key foundational components involved in training and tuning generative AI models: refinement algorithms, hyperparameters, and datasets.

---

## 🛠️ Refinement Algorithms and Denoising

- Used to **gradually improve generated outputs** such as images.
- Changes aren’t made all at once—they happen in **small steps**.
- This step-by-step correction process is called **denoising**.

> “Improvements are not done all at once. Gradual improvements are made until the image is deemed high quality… This process is known as the denoising process.”

---

## ⚙️ Hyperparameters and Parameters

- A **parameter** is a variable adjusted during model training that affects how data transforms from input to output.
  - Example: A smart thermostat trained to turn off when nobody is home—this behavior is shaped by a parameter.

- A **hyperparameter** is set **before** the model is trained.
  - Controls how the model learns, such as:
    - Learning rate
    - Training duration
    - Model complexity

> Example: A smart home device with a **high learning rating** adapts quickly to a user’s energy needs.  
> If the learning rating is **low**, it takes longer to optimize.

---

## 🧾 What Is a Dataset?

- A **dataset** contains the structured data used to train, validate, and test an AI model.

### Example:
- **MNIST dataset**:
  - 60,000 training images
  - 10,000 testing images
  - This ratio is common for many AI training setups

### Application:
- To train a smart home energy model:
  - Use a dataset of **energy usage patterns**
  - Include variables like:
    - Temperature
    - Number of occupants
    - Time of day
    - Weather conditions

---

## 💡 Key Insight

Successful AI training relies on:
- Smart **hyperparameter tuning**
- Clean and well-structured **datasets**
- Iterative **refinement** processes like denoising

