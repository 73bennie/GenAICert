# Lesson 3.c â€“ Algorithms, Hyperparameters, and Datasets

### ðŸŽ¯ Lesson Objective
Clarify key foundational components involved in training and tuning generative AI models: refinement algorithms, hyperparameters, and datasets.

---

## ðŸ› ï¸ Refinement Algorithms and Denoising

- Used to **gradually improve generated outputs** such as images.
- Changes arenâ€™t made all at onceâ€”they happen in **small steps**.
- This step-by-step correction process is called **denoising**.

> â€œImprovements are not done all at once. Gradual improvements are made until the image is deemed high qualityâ€¦ This process is known as the denoising process.â€

---

## âš™ï¸ Hyperparameters and Parameters

- A **parameter** is a variable adjusted during model training that affects how data transforms from input to output.
  - Example: A smart thermostat trained to turn off when nobody is homeâ€”this behavior is shaped by a parameter.

- A **hyperparameter** is set **before** the model is trained.
  - Controls how the model learns, such as:
    - Learning rate
    - Training duration
    - Model complexity

> Example: A smart home device with a **high learning rating** adapts quickly to a userâ€™s energy needs.  
> If the learning rating is **low**, it takes longer to optimize.

---

## ðŸ§¾ What Is a Dataset?

- A **dataset** contains the structured data used to train, validate, and test an AI model.

### Example:
- **MNIST dataset**:
  - 60,000 training images
  - 10,000 testing images
  - This ratio is common for many AI training setups

### Application:
- To train a smart home energy model:
  - Use a dataset of **energy usage patterns**
  - Include variables like:
    - Temperature
    - Number of occupants
    - Time of day
    - Weather conditions

---

## ðŸ’¡ Key Insight

Successful AI training relies on:
- Smart **hyperparameter tuning**
- Clean and well-structured **datasets**
- Iterative **refinement** processes like denoising

